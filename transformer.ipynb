{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pipenv install --python 3.10\n",
        "# pipenv shell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_JliZu9T64K"
      },
      "source": [
        "# TODO:\n",
        "# using pretrain embedding with transformer on smaller dataset\n",
        "# using depth-wise-separable 1D convolution based model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# %pip install -q --upgrade keras-nlp\n",
        "# %pip install -q --upgrade keras  # Upgrade to Keras 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-24 15:06:44.076044: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-03-24 15:06:44.080575: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-03-24 15:06:44.159000: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-03-24 15:06:45.866534: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "import keras\n",
        "from keras import layers\n",
        "import keras_nlp\n",
        "from keras_nlp import layers as nlp_layers\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlAN0hTMT64Q"
      },
      "source": [
        "**Download the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "\u001b[1m84125825/84125825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "keras.utils.get_file(\n",
        "    origin=\"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "    cache_dir=\"./\",\n",
        "    extract=True\n",
        ")\n",
        "\n",
        "imdb_dir = Path(\"./datasets/aclImdb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[01;34mdatasets/aclImdb/\u001b[0m\n",
            "├── \u001b[01;34mtest\u001b[0m\n",
            "│   ├── \u001b[01;34mneg\u001b[0m\n",
            "│   └── \u001b[01;34mpos\u001b[0m\n",
            "└── \u001b[01;34mtrain\u001b[0m\n",
            "    ├── \u001b[01;34mneg\u001b[0m\n",
            "    ├── \u001b[01;34mpos\u001b[0m\n",
            "    └── \u001b[01;34munsup\u001b[0m\n",
            "\n",
            "8 directories\n"
          ]
        }
      ],
      "source": [
        "!tree -d datasets/aclImdb/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kOSUbWqT64V"
      },
      "source": [
        "remove unsupervised training data, we don't need that here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JvJEiFXST64V"
      },
      "outputs": [],
      "source": [
        "!rm -r datasets/aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[01;34mdatasets/aclImdb/\u001b[0m\n",
            "├── \u001b[01;34mtest\u001b[0m\n",
            "│   ├── \u001b[01;34mneg\u001b[0m\n",
            "│   └── \u001b[01;34mpos\u001b[0m\n",
            "└── \u001b[01;34mtrain\u001b[0m\n",
            "    ├── \u001b[01;34mneg\u001b[0m\n",
            "    └── \u001b[01;34mpos\u001b[0m\n",
            "\n",
            "7 directories\n"
          ]
        }
      ],
      "source": [
        "!tree -d datasets/aclImdb/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM81Pp54T64W"
      },
      "source": [
        "quick look at one review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atmjYAMKT64W",
        "outputId": "46c4d555-fa95-4e58-a23a-7d8589782cf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What was with all the Turkish actors? No offense but I thought it was all for nothing for all these actors. The film had no script to test any actors acting skill or ability. It demanded next to nothing I bought this film to see Michael Madsen. He is one of my favorite actors but this film was another failure for him. The script was so bad. Their was just nothing to sink your teeth into and all the characters were two dimensional. Madsen tried to act like a hard ass but the script and direction didn't even allow him to do enough with his character to make it more interesting or 3 dimensional.<br /><br />Even the sound effects of the gunfight at the beginning of the film sounded like the noise of paint ball guns when they are fired in a skirmish. It was really weird and they didn't sound like real guns. A video game had better sound effects than this film. There was also a really annoying bloke at the beginning of the film who was a member of the robbery gang. He had this American whining voice like a girl shouting lines like \"Lets get the F#$k out of here\" and What are we going to do man\". He sounded like a girl. As a positive It was funny to watch and it made me laugh too. For a few seconds. Whoo Hoo ! Dumb Film. Poor Madsen. He will bounce back..."
          ]
        }
      ],
      "source": [
        "!cat datasets/aclImdb/train/neg/21_4.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z66wMQ-dT64X"
      },
      "source": [
        "prepare validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nrLfJ140T64X"
      },
      "outputs": [],
      "source": [
        "import os, shutil, random\n",
        "\n",
        "validation_dir = imdb_dir / \"validation\"\n",
        "validation_dir.mkdir()\n",
        "train_dir = imdb_dir / \"train\"\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    (validation_dir / category).mkdir()\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1234).shuffle(files)  # use seed to ensure same dataset through different runs\n",
        "    num_validation_samples = int(0.2 * len(files))\n",
        "    validation_files = files[-num_validation_samples:]\n",
        "    for file in validation_files:\n",
        "        shutil.move(train_dir / category / file,\n",
        "                    validation_dir / category / file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[01;34mdatasets/aclImdb/\u001b[0m\n",
            "├── \u001b[01;34mtest\u001b[0m\n",
            "│   ├── \u001b[01;34mneg\u001b[0m\n",
            "│   └── \u001b[01;34mpos\u001b[0m\n",
            "├── \u001b[01;34mtrain\u001b[0m\n",
            "│   ├── \u001b[01;34mneg\u001b[0m\n",
            "│   └── \u001b[01;34mpos\u001b[0m\n",
            "└── \u001b[01;34mvalidation\u001b[0m\n",
            "    ├── \u001b[01;34mneg\u001b[0m\n",
            "    └── \u001b[01;34mpos\u001b[0m\n",
            "\n",
            "10 directories\n"
          ]
        }
      ],
      "source": [
        "!tree -d datasets/aclImdb/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYV5zS6XT64X",
        "outputId": "73ece954-c00b-4a82-ac4e-93a5eaa26dea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "# 0 for negative, 1 for positive\n",
        "train_dataset = keras.utils.text_dataset_from_directory(\n",
        "    \"datasets/aclImdb/train\", batch_size=batch_size)\n",
        "validation_dataset = keras.utils.text_dataset_from_directory(\n",
        "    \"datasets/aclImdb/validation\", batch_size=batch_size)\n",
        "test_dataset = keras.utils.text_dataset_from_directory(\n",
        "    \"datasets/aclImdb/test\", batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWF_yM8oT64Y"
      },
      "source": [
        "take a look at the batch data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8mSyCqYT64Y",
        "outputId": "11f74901-6a53-48cb-c28a-e663a8d10384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs.shape:  (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b\"I have to start off by apologizing because I thought the first 75-80% of this film was hilarious. It's mostly because of Brad Pitt's performance. Spot on.<br /><br />The acting by all involved was quite good but Brad stole the movie. The atmosphere was perfect in all respects. I'm not a giant Pitt fan but this has got to be one of his best roles ever.<br /><br />Brutal,Honest,Gritty. All good words to describe this movie.<br /><br />I was reading a previous review and the person said that the reasoning behind Early's violence isn't explained. It is explained but they thankfully don't have to go into graphic detail to get their point across.<br /><br />Overall I gave this a 9 because every scene bar 1 or 2 was effective. I think the humor in the first half or so is perfect for this movie. Underrated.\", shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_dataset:\n",
        "    print(\"inputs.shape: \", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "prepare a text vectorization layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-24 15:12:07.206559: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        }
      ],
      "source": [
        "text_only_train_dataset = train_dataset.map(lambda x, y: x)  # do not need labels to train the text vectorization layer\n",
        "\n",
        "max_length = 600\n",
        "max_tokens = 20_000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length)\n",
        "\n",
        "text_vectorization.adapt(text_only_train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YBOnN7eT64Z"
      },
      "source": [
        "prepare integer sequence datasets "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TIGkJSgQT64Z"
      },
      "outputs": [],
      "source": [
        "int_train_dataset = train_dataset.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_validation_dataset = validation_dataset.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_test_dataset = test_dataset.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "use keras built-in transformer encoder for text classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "transformer_encoder = nlp_layers.TransformerEncoder(intermediate_dim=32, \n",
        "                                                    num_heads=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kK9QrWBT64a"
      },
      "source": [
        "use the transformer encoder for text classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLi1x4vDT64a",
        "outputId": "c6307e91-4e5c-4af6-d083-dc19cb2f44cc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ token_and_position_embedding_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,273,600</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)     │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_encoder_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">280,864</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ token_and_position_embedding_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m5,273,600\u001b[0m │\n",
              "│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)     │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_encoder_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m280,864\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,554,721</span> (21.19 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,554,721\u001b[0m (21.19 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,554,721</span> (21.19 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,554,721\u001b[0m (21.19 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "vocabulary_size = 20_000\n",
        "sequence_length = 600\n",
        "embed_dimension = 256\n",
        "\n",
        "num_heads = 2\n",
        "dense_layer_dimension = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "\n",
        "x = nlp_layers.TokenAndPositionEmbedding(vocabulary_size=vocabulary_size,\n",
        "                                         sequence_length=sequence_length,\n",
        "                                         embedding_dim=embed_dimension\n",
        "                                         )(inputs)\n",
        "x = nlp_layers.TransformerEncoder(intermediate_dim=dense_layer_dimension,\n",
        "                                  num_heads=num_heads\n",
        "                                  )(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E740hFZbT64a"
      },
      "source": [
        "train the transformer encoder model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaRnc5OxT64a",
        "outputId": "f0435c88-5265-4d13-f71e-43f83d4739a7"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"trained_models/transformer_encoder.keras\",\n",
        "        save_best_only=True)]\n",
        "\n",
        "model.fit(int_train_dataset,\n",
        "          validation_data=int_validation_dataset,\n",
        "          epochs=3, # 20\n",
        "          callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "evaluate the transformer encoder model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\n",
        "    \"trained_models/transformer_encoder.keras\")\n",
        "\n",
        "print(f\"Test accuracy: {model.evaluate(int_test_dataset)[1]:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
