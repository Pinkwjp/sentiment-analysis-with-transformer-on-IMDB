{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99FtGlbaICie"
      },
      "outputs": [],
      "source": [
        "# pipenv install --python 3.10\n",
        "# pipenv shell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjox6IF3JxLd"
      },
      "source": [
        "**run this cell when running on colab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoGQMZjmICil",
        "outputId": "c51df6c4-68d9-41c0-c3f9-f64dc8fc13aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/465.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m317.4/465.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.8/286.8 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# create folder\n",
        "from pathlib import Path\n",
        "\n",
        "trained_model_folder = Path(\"./trained_models/\")\n",
        "\n",
        "if not trained_model_folder.exists():\n",
        "    trained_model_folder.mkdir()\n",
        "\n",
        "# install tree\n",
        "!apt-get install tree\n",
        "\n",
        "# install libraries\n",
        "%pip install -q --upgrade keras-nlp  # install keras-nlp before keras\n",
        "%pip install -q --upgrade keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10VfiCnaICin"
      },
      "source": [
        "**Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x_pxn9cCICio"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import keras_nlp\n",
        "from keras_nlp import layers as nlp_layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlAN0hTMT64Q"
      },
      "source": [
        "**Download the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiLAG9lSICip",
        "outputId": "b7f670b8-f215-4fe8-cd5b-db6fa9faf4cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "\u001b[1m84125825/84125825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "keras.utils.get_file(\n",
        "    origin=\"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "    cache_dir=\"./\",\n",
        "    extract=True\n",
        ")\n",
        "\n",
        "imdb_dir = Path(\"./datasets/aclImdb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3Q39A3GICiq",
        "outputId": "3aadae30-8436-4c9e-f186-f698fd5b1593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[01;34mdatasets/aclImdb/\u001b[0m\n",
            "├── \u001b[01;34mtest\u001b[0m\n",
            "│   ├── \u001b[01;34mneg\u001b[0m\n",
            "│   └── \u001b[01;34mpos\u001b[0m\n",
            "└── \u001b[01;34mtrain\u001b[0m\n",
            "    ├── \u001b[01;34mneg\u001b[0m\n",
            "    ├── \u001b[01;34mpos\u001b[0m\n",
            "    └── \u001b[01;34munsup\u001b[0m\n",
            "\n",
            "7 directories\n"
          ]
        }
      ],
      "source": [
        "!tree -d datasets/aclImdb/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kOSUbWqT64V"
      },
      "source": [
        "remove unsupervised training data, we don't need that here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JvJEiFXST64V"
      },
      "outputs": [],
      "source": [
        "!rm -r datasets/aclImdb/train/unsup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNfLsbGjICir",
        "outputId": "81c91f4a-f4f6-43cc-cfda-17b2323c2832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[01;34mdatasets/aclImdb/\u001b[0m\n",
            "├── \u001b[01;34mtest\u001b[0m\n",
            "│   ├── \u001b[01;34mneg\u001b[0m\n",
            "│   └── \u001b[01;34mpos\u001b[0m\n",
            "└── \u001b[01;34mtrain\u001b[0m\n",
            "    ├── \u001b[01;34mneg\u001b[0m\n",
            "    └── \u001b[01;34mpos\u001b[0m\n",
            "\n",
            "6 directories\n"
          ]
        }
      ],
      "source": [
        "!tree -d datasets/aclImdb/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM81Pp54T64W"
      },
      "source": [
        "quick look at one review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atmjYAMKT64W",
        "outputId": "6009f525-9636-4e38-8674-2e56970354cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What was with all the Turkish actors? No offense but I thought it was all for nothing for all these actors. The film had no script to test any actors acting skill or ability. It demanded next to nothing I bought this film to see Michael Madsen. He is one of my favorite actors but this film was another failure for him. The script was so bad. Their was just nothing to sink your teeth into and all the characters were two dimensional. Madsen tried to act like a hard ass but the script and direction didn't even allow him to do enough with his character to make it more interesting or 3 dimensional.<br /><br />Even the sound effects of the gunfight at the beginning of the film sounded like the noise of paint ball guns when they are fired in a skirmish. It was really weird and they didn't sound like real guns. A video game had better sound effects than this film. There was also a really annoying bloke at the beginning of the film who was a member of the robbery gang. He had this American whining voice like a girl shouting lines like \"Lets get the F#$k out of here\" and What are we going to do man\". He sounded like a girl. As a positive It was funny to watch and it made me laugh too. For a few seconds. Whoo Hoo ! Dumb Film. Poor Madsen. He will bounce back..."
          ]
        }
      ],
      "source": [
        "!cat datasets/aclImdb/train/neg/21_4.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z66wMQ-dT64X"
      },
      "source": [
        "prepare validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nrLfJ140T64X"
      },
      "outputs": [],
      "source": [
        "import os, shutil, random\n",
        " \n",
        "validation_dir = imdb_dir / \"validation\"\n",
        "validation_dir.mkdir()\n",
        "train_dir = imdb_dir / \"train\"\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    (validation_dir / category).mkdir()\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1234).shuffle(files)  # use seed to ensure same dataset through different runs\n",
        "    num_validation_samples = int(0.2 * len(files))\n",
        "    validation_files = files[-num_validation_samples:]\n",
        "    for file in validation_files:\n",
        "        shutil.move(train_dir / category / file,\n",
        "                    validation_dir / category / file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6OVyfH7ICit",
        "outputId": "7ec2871f-1b60-4f94-ca4e-bcd07fe6bb12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[01;34mdatasets/aclImdb/\u001b[0m\n",
            "├── \u001b[01;34mtest\u001b[0m\n",
            "│   ├── \u001b[01;34mneg\u001b[0m\n",
            "│   └── \u001b[01;34mpos\u001b[0m\n",
            "├── \u001b[01;34mtrain\u001b[0m\n",
            "│   ├── \u001b[01;34mneg\u001b[0m\n",
            "│   └── \u001b[01;34mpos\u001b[0m\n",
            "└── \u001b[01;34mvalidation\u001b[0m\n",
            "    ├── \u001b[01;34mneg\u001b[0m\n",
            "    └── \u001b[01;34mpos\u001b[0m\n",
            "\n",
            "9 directories\n"
          ]
        }
      ],
      "source": [
        "!tree -d datasets/aclImdb/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYV5zS6XT64X",
        "outputId": "f9e89e19-dbcb-47f7-95f1-b2d85a2e1de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "# 0 for negative, 1 for positive\n",
        "train_dataset = keras.utils.text_dataset_from_directory(\n",
        "    \"datasets/aclImdb/train\", batch_size=batch_size)\n",
        "validation_dataset = keras.utils.text_dataset_from_directory(\n",
        "    \"datasets/aclImdb/validation\", batch_size=batch_size)\n",
        "test_dataset = keras.utils.text_dataset_from_directory(\n",
        "    \"datasets/aclImdb/test\", batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWF_yM8oT64Y"
      },
      "source": [
        "take a look at the batch data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8mSyCqYT64Y",
        "outputId": "fdd3a9c6-5ce8-49f9-8ba9-663a05e8da57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs.shape:  (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b\"I am a huge fan of Say Anything, Jerry Maguire, and Almost Famous (I wasn't that big on Singles), so it's safe to say that I look forward to anything that Cameron Crowe attaches his name to. I went to see Vanilla Sky having been told that it was a very weird movie and that I probably wouldn't like it if I was expecting anything similar to Crowe's other films. Well, having just seen it, let me say that the former was correct, and the latter couldn't have been more wrong. It is a very weird movie, and nothing really comes together until the end. Anyone who tells you that they saw it coming halfway into the movie is either lying to you or is unable to detach their hindsight from their memory. Anyway, the movie was stellar, and I look forward to owning it as soon as the DVD is released. I was moved by the film, and felt emotionally spent by the end. This is an experience that will draw from the viewer the entire spectrum of human emotion, if the viewer allows him/herself into the plot. In the theatre in which I saw the movie, there were more than a few people who clearly lost track of the movie and were bored by it when they found that they were unable to get back into the plot. I'm sure others just lack the ability to properly follow any movie like this. I don't mean that to sound pompous, but some people are more cut out for the Seagal, Chan, Van Damme genre of movies, and these are the types that probably would not enjoy this movie. It is very cerebral, so make sure you are prepared for a two hour mental bender, as well as much thought afterwards.<br /><br />As far as comparing this film to other Crowe movies, it is very similar in at least one regard, in all Crowe movies, the soundtrack is a character unto itself. This is almost definitely due to Crowe's longstanding ties to music, as anyone who has seen Almost Famous knows, and to his marriage to Heart star Nancy Wilson. It was also worthy to note that there was a definite chemistry between Tom Cruise's acting and Crowe's directing that made the movie seem familiar to anyone who has seen Jerry Maguire. In my mind, that is not a bad thing.<br /><br />Anyway, if I had to compare this movie to any one other film, I would say this: if you enjoyed David Fincher's The Game, you will almost certainly be a fan of Vanilla Sky.\", shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_dataset:\n",
        "    print(\"inputs.shape: \", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdUCKZXfICiu"
      },
      "source": [
        "train a text vectorization layer with unlabeled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qmcDi88cICiu"
      },
      "outputs": [],
      "source": [
        "text_only_train_dataset = train_dataset.map(lambda x, y: x)  # do not need labels to train the text vectorization layer\n",
        "\n",
        "max_length = 600\n",
        "max_tokens = 20_000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length)\n",
        "\n",
        "text_vectorization.adapt(text_only_train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YBOnN7eT64Z"
      },
      "source": [
        "prepare integer sequence datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TIGkJSgQT64Z"
      },
      "outputs": [],
      "source": [
        "int_train_dataset = train_dataset.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_validation_dataset = validation_dataset.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_test_dataset = test_dataset.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kK9QrWBT64a"
      },
      "source": [
        "use a TransformerEncoder-based model for text classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "uLi1x4vDT64a",
        "outputId": "43e1c30e-0a2f-45c1-d970-e45539552308"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ token_and_position_embedding         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,273,600</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">280,864</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ token_and_position_embedding         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m5,273,600\u001b[0m │\n",
              "│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m280,864\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m257\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,554,721</span> (21.19 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,554,721\u001b[0m (21.19 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,554,721</span> (21.19 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,554,721\u001b[0m (21.19 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "vocabulary_size = 20_000\n",
        "sequence_length = 600\n",
        "embed_dimension = 32\n",
        "\n",
        "num_heads = 2\n",
        "dense_layer_dimension = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "\n",
        "x = nlp_layers.TokenAndPositionEmbedding(vocabulary_size=vocabulary_size,\n",
        "                                         sequence_length=sequence_length,\n",
        "                                         embedding_dim=embed_dimension\n",
        "                                         )(inputs)\n",
        "\n",
        "x = nlp_layers.TransformerEncoder(intermediate_dim=dense_layer_dimension,\n",
        "                                  num_heads=num_heads\n",
        "                                  )(x)\n",
        "\n",
        "# x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)  # 0.5\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E740hFZbT64a"
      },
      "source": [
        "train the transformer encoder model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaRnc5OxT64a",
        "outputId": "0cde8cbe-043d-4938-b341-523edaebf23c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 110ms/step - accuracy: 0.6131 - loss: 0.8031 - val_accuracy: 0.8220 - val_loss: 0.4059\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 81ms/step - accuracy: 0.8047 - loss: 0.4238 - val_accuracy: 0.8396 - val_loss: 0.3771\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 80ms/step - accuracy: 0.8381 - loss: 0.3649 - val_accuracy: 0.8420 - val_loss: 0.3500\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 83ms/step - accuracy: 0.8660 - loss: 0.3195 - val_accuracy: 0.8266 - val_loss: 0.3779\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 82ms/step - accuracy: 0.8827 - loss: 0.2839 - val_accuracy: 0.8504 - val_loss: 0.3408\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 82ms/step - accuracy: 0.9035 - loss: 0.2481 - val_accuracy: 0.8546 - val_loss: 0.3385\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 80ms/step - accuracy: 0.9223 - loss: 0.1997 - val_accuracy: 0.8554 - val_loss: 0.3490\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 80ms/step - accuracy: 0.9393 - loss: 0.1584 - val_accuracy: 0.8506 - val_loss: 0.3802\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 79ms/step - accuracy: 0.9535 - loss: 0.1246 - val_accuracy: 0.8504 - val_loss: 0.4072\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 77ms/step - accuracy: 0.9653 - loss: 0.0927 - val_accuracy: 0.8342 - val_loss: 0.4669\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 75ms/step - accuracy: 0.9790 - loss: 0.0622 - val_accuracy: 0.8474 - val_loss: 0.4609\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 69ms/step - accuracy: 0.9844 - loss: 0.0464 - val_accuracy: 0.8342 - val_loss: 0.5694\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 66ms/step - accuracy: 0.9883 - loss: 0.0348 - val_accuracy: 0.8330 - val_loss: 0.5909\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.9917 - loss: 0.0245 - val_accuracy: 0.8404 - val_loss: 0.5641\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 60ms/step - accuracy: 0.9919 - loss: 0.0231 - val_accuracy: 0.8412 - val_loss: 0.6750\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 58ms/step - accuracy: 0.9935 - loss: 0.0198 - val_accuracy: 0.8472 - val_loss: 0.6843\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 57ms/step - accuracy: 0.9927 - loss: 0.0201 - val_accuracy: 0.8190 - val_loss: 0.8384\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 56ms/step - accuracy: 0.9938 - loss: 0.0202 - val_accuracy: 0.8344 - val_loss: 0.7895\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 54ms/step - accuracy: 0.9953 - loss: 0.0151 - val_accuracy: 0.8414 - val_loss: 0.7541\n",
            "Epoch 20/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 54ms/step - accuracy: 0.9924 - loss: 0.0189 - val_accuracy: 0.8482 - val_loss: 0.7942\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7db5a667ce50>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"trained_models/transformer_encoder.keras\",\n",
        "        save_best_only=True)]\n",
        "\n",
        "model.fit(int_train_dataset,\n",
        "          validation_data=int_validation_dataset,\n",
        "          epochs=6,\n",
        "          callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59kyt5UNICiw"
      },
      "source": [
        "evaluate the transformer encoder model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl1Sb-WHICiw",
        "outputId": "41cc8c24-bd37-4e76-c110-b8256df60195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.8502 - loss: 0.3496\n",
            "Test accuracy: 0.851\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\n",
        "    \"trained_models/transformer_encoder.keras\")\n",
        "\n",
        "print(f\"Test accuracy: {model.evaluate(int_test_dataset)[1]:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
